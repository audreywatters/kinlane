<!DOCTYPE html>
<html lang="en">

    <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Why Would People Want Fine Art Trained Machine Learning Models | Kin Lane</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="Why Would People Want Fine Art Trained Machine Learning Models" />
<meta name="author" content="Kin Lane" />
<meta property="og:locale" content="en" />
<meta name="description" content="I&#39;m spending time on my algorithmic rotoscope work, and thinking about how the machine learning style textures I&#39;ve been marking can be put to use. I&#39;m trying to see things from different vantage points and develop a better understanding of how texture styles can be put to use in the regular world. I am enjoying using image style filters in my writing. It gives me kind of a gamified layer to my photography and drone hobby that allows me to create actual images I can use in my work as the API Evangelist. Having unique filtered images available for use in my writing is valuable to me--enough to justify the couple hundreds of dollars I spend each month on AWS servers. I know why I like applying image styles to my photos, but why do others? Most of the image filters out there we&#39;ve seen from apps like Prisma are focused on fine art. Training image style transfer machine learning models on popular art that people are already familiar with. I guess this is allows people to apply the characteristics of art they like to the photographic layer of our increasingly digital lives. To me, it feels like some sort of art placebo. A way of superficially and algorithmic injecting what are brain tells us is artsy to our fairly empty, digital photo reality. Taking photos in real time isn&#39;t satisfying enough anymore. We need to distract ourselves from the world by applying reality to our digitally documented physical world--almost the opposite of augmented reality if there is such a thing. Getting lost in the ability to look at the real world through the algorithmic lens of our online life. We are stealing the essence the meaningful, tangible art from our real world, and digitizing it. We take this essense and algorithmically apply it our everyday life trying to add some color, some texture, but not too much. We need the photos to still be meaningful, and have context in our life, but we need to be able to spray an algorithmic lacquer of meaning on our intangible lives. The more filters we have, the more lenses we have to look at the exact same moment we live each day. We go to work. We go to school. We see the same scenery, the same people, and the same pictures each day. Now we are able to algorithmic shift, distort, and paint the picture of our lives we want to see. Now we can add color to our life. We are being trained to think we can change the palette, and are in control over our lives. We can colorize the old World War 2 era photos of our day, and choose whether we want to color within, or outside the lines. Our lives don&#39;t have to be just binary 1s and 0s, and black or white. Slowly, picture by picture, algorithmic transfer by algorithmic transfer, the way we see the world changes. We no longer settle for the way things are, the way our mobile phone camera catches it. The digital version is the image we share with my friends, family, and the world. It should always be the most brilliant, the most colorful, and the painting that catches their eye and makes them stand in front of on the wall of your Facebook feed captivated. We no longer will remember what reality looks like, or what art looks like. Our collective social media memory will dictate what the world looks like. The number of likes will determine what is artistic, and what is beautiful or ugly. The algorithm will only show us what images match the world it wants us to see. Algorithmically, artistically painting the inside walls of our digital bubble. Eventually, the sensors that stimulate us when we see photos will be well worn. They will be well programmed, with known inputs, and predictable outputs. The algorithm will be able to deliver exactly what we need, and correctly predict what we will need next. Scheduling up and queuing the next fifty possible scenarios--with exactly the right colors, textures, and meaning. How we see art will be forever changed by the algorithm. Our machines will never see art. Our machines will never know art. Our machines will only be able to transfer the characteristics we see and deliver them into newer, more relevant, timely, and meaningful images. Distilling down the essence of art into binary, and programming us to think this synthetic art is meaningful, and still applies to our physical world. Like I said, I think people like applying artistic image filters to their mobile photos because it is the opposite of augmented reality. They are trying to augment their digital (hopes of reality) presence with the essence of what we (algorithm) think matters to use in the world. This process isn&#39;t about training a model to see art like some folks may tell you. It is about distilling down some of the most simple aspects of what our eyes see as art, and give this algorithm to our mobile phones and social networks to apply to the photograph digital logging of our physical reality. It feels like this is about reprogramming people. It is about reprogramming what stimulates you. Automating an algorithmic view of what matters when it comes to art, and applying it to a digital view of matters in our daily worlds, via our social networks. Just one more area of our life where we are allowing algorithms to reprogram us, and bend our reality to be more digital. I Borrowed This Image From University of Maine Museum of Art" />
<meta property="og:description" content="I&#39;m spending time on my algorithmic rotoscope work, and thinking about how the machine learning style textures I&#39;ve been marking can be put to use. I&#39;m trying to see things from different vantage points and develop a better understanding of how texture styles can be put to use in the regular world. I am enjoying using image style filters in my writing. It gives me kind of a gamified layer to my photography and drone hobby that allows me to create actual images I can use in my work as the API Evangelist. Having unique filtered images available for use in my writing is valuable to me--enough to justify the couple hundreds of dollars I spend each month on AWS servers. I know why I like applying image styles to my photos, but why do others? Most of the image filters out there we&#39;ve seen from apps like Prisma are focused on fine art. Training image style transfer machine learning models on popular art that people are already familiar with. I guess this is allows people to apply the characteristics of art they like to the photographic layer of our increasingly digital lives. To me, it feels like some sort of art placebo. A way of superficially and algorithmic injecting what are brain tells us is artsy to our fairly empty, digital photo reality. Taking photos in real time isn&#39;t satisfying enough anymore. We need to distract ourselves from the world by applying reality to our digitally documented physical world--almost the opposite of augmented reality if there is such a thing. Getting lost in the ability to look at the real world through the algorithmic lens of our online life. We are stealing the essence the meaningful, tangible art from our real world, and digitizing it. We take this essense and algorithmically apply it our everyday life trying to add some color, some texture, but not too much. We need the photos to still be meaningful, and have context in our life, but we need to be able to spray an algorithmic lacquer of meaning on our intangible lives. The more filters we have, the more lenses we have to look at the exact same moment we live each day. We go to work. We go to school. We see the same scenery, the same people, and the same pictures each day. Now we are able to algorithmic shift, distort, and paint the picture of our lives we want to see. Now we can add color to our life. We are being trained to think we can change the palette, and are in control over our lives. We can colorize the old World War 2 era photos of our day, and choose whether we want to color within, or outside the lines. Our lives don&#39;t have to be just binary 1s and 0s, and black or white. Slowly, picture by picture, algorithmic transfer by algorithmic transfer, the way we see the world changes. We no longer settle for the way things are, the way our mobile phone camera catches it. The digital version is the image we share with my friends, family, and the world. It should always be the most brilliant, the most colorful, and the painting that catches their eye and makes them stand in front of on the wall of your Facebook feed captivated. We no longer will remember what reality looks like, or what art looks like. Our collective social media memory will dictate what the world looks like. The number of likes will determine what is artistic, and what is beautiful or ugly. The algorithm will only show us what images match the world it wants us to see. Algorithmically, artistically painting the inside walls of our digital bubble. Eventually, the sensors that stimulate us when we see photos will be well worn. They will be well programmed, with known inputs, and predictable outputs. The algorithm will be able to deliver exactly what we need, and correctly predict what we will need next. Scheduling up and queuing the next fifty possible scenarios--with exactly the right colors, textures, and meaning. How we see art will be forever changed by the algorithm. Our machines will never see art. Our machines will never know art. Our machines will only be able to transfer the characteristics we see and deliver them into newer, more relevant, timely, and meaningful images. Distilling down the essence of art into binary, and programming us to think this synthetic art is meaningful, and still applies to our physical world. Like I said, I think people like applying artistic image filters to their mobile photos because it is the opposite of augmented reality. They are trying to augment their digital (hopes of reality) presence with the essence of what we (algorithm) think matters to use in the world. This process isn&#39;t about training a model to see art like some folks may tell you. It is about distilling down some of the most simple aspects of what our eyes see as art, and give this algorithm to our mobile phones and social networks to apply to the photograph digital logging of our physical reality. It feels like this is about reprogramming people. It is about reprogramming what stimulates you. Automating an algorithmic view of what matters when it comes to art, and applying it to a digital view of matters in our daily worlds, via our social networks. Just one more area of our life where we are allowing algorithms to reprogram us, and bend our reality to be more digital. I Borrowed This Image From University of Maine Museum of Art" />
<link rel="canonical" href="http://localhost:4000/2017/03/08/why-would-people-want-fine-art-trained-machine-learning-models/" />
<meta property="og:url" content="http://localhost:4000/2017/03/08/why-would-people-want-fine-art-trained-machine-learning-models/" />
<meta property="og:site_name" content="Kin Lane" />
<meta property="og:image" content="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/art-museum/art-museum_blue_brush.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-03-08T00:00:00-05:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/art-museum/art-museum_blue_brush.jpg" />
<meta property="twitter:title" content="Why Would People Want Fine Art Trained Machine Learning Models" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Kin Lane"},"dateModified":"2017-03-08T00:00:00-05:00","datePublished":"2017-03-08T00:00:00-05:00","description":"I&#39;m spending time on my algorithmic rotoscope work, and thinking about how the machine learning style textures I&#39;ve been marking can be put to use. I&#39;m trying to see things from different vantage points and develop a better understanding of how texture styles can be put to use in the regular world. I am enjoying using image style filters in my writing. It gives me kind of a gamified layer to my photography and drone hobby that allows me to create actual images I can use in my work as the API Evangelist. Having unique filtered images available for use in my writing is valuable to me--enough to justify the couple hundreds of dollars I spend each month on AWS servers. I know why I like applying image styles to my photos, but why do others? Most of the image filters out there we&#39;ve seen from apps like Prisma are focused on fine art. Training image style transfer machine learning models on popular art that people are already familiar with. I guess this is allows people to apply the characteristics of art they like to the photographic layer of our increasingly digital lives. To me, it feels like some sort of art placebo. A way of superficially and algorithmic injecting what are brain tells us is artsy to our fairly empty, digital photo reality. Taking photos in real time isn&#39;t satisfying enough anymore. We need to distract ourselves from the world by applying reality to our digitally documented physical world--almost the opposite of augmented reality if there is such a thing. Getting lost in the ability to look at the real world through the algorithmic lens of our online life. We are stealing the essence the meaningful, tangible art from our real world, and digitizing it. We take this essense and algorithmically apply it our everyday life trying to add some color, some texture, but not too much. We need the photos to still be meaningful, and have context in our life, but we need to be able to spray an algorithmic lacquer of meaning on our intangible lives. The more filters we have, the more lenses we have to look at the exact same moment we live each day. We go to work. We go to school. We see the same scenery, the same people, and the same pictures each day. Now we are able to algorithmic shift, distort, and paint the picture of our lives we want to see. Now we can add color to our life. We are being trained to think we can change the palette, and are in control over our lives. We can colorize the old World War 2 era photos of our day, and choose whether we want to color within, or outside the lines. Our lives don&#39;t have to be just binary 1s and 0s, and black or white. Slowly, picture by picture, algorithmic transfer by algorithmic transfer, the way we see the world changes. We no longer settle for the way things are, the way our mobile phone camera catches it. The digital version is the image we share with my friends, family, and the world. It should always be the most brilliant, the most colorful, and the painting that catches their eye and makes them stand in front of on the wall of your Facebook feed captivated. We no longer will remember what reality looks like, or what art looks like. Our collective social media memory will dictate what the world looks like. The number of likes will determine what is artistic, and what is beautiful or ugly. The algorithm will only show us what images match the world it wants us to see. Algorithmically, artistically painting the inside walls of our digital bubble. Eventually, the sensors that stimulate us when we see photos will be well worn. They will be well programmed, with known inputs, and predictable outputs. The algorithm will be able to deliver exactly what we need, and correctly predict what we will need next. Scheduling up and queuing the next fifty possible scenarios--with exactly the right colors, textures, and meaning. How we see art will be forever changed by the algorithm. Our machines will never see art. Our machines will never know art. Our machines will only be able to transfer the characteristics we see and deliver them into newer, more relevant, timely, and meaningful images. Distilling down the essence of art into binary, and programming us to think this synthetic art is meaningful, and still applies to our physical world. Like I said, I think people like applying artistic image filters to their mobile photos because it is the opposite of augmented reality. They are trying to augment their digital (hopes of reality) presence with the essence of what we (algorithm) think matters to use in the world. This process isn&#39;t about training a model to see art like some folks may tell you. It is about distilling down some of the most simple aspects of what our eyes see as art, and give this algorithm to our mobile phones and social networks to apply to the photograph digital logging of our physical reality. It feels like this is about reprogramming people. It is about reprogramming what stimulates you. Automating an algorithmic view of what matters when it comes to art, and applying it to a digital view of matters in our daily worlds, via our social networks. Just one more area of our life where we are allowing algorithms to reprogram us, and bend our reality to be more digital. I Borrowed This Image From University of Maine Museum of Art","headline":"Why Would People Want Fine Art Trained Machine Learning Models","image":"https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/art-museum/art-museum_blue_brush.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2017/03/08/why-would-people-want-fine-art-trained-machine-learning-models/"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://kinlane-productions2.s3.amazonaws.com/kin-lane/kin.png"},"name":"Kin Lane"},"url":"http://localhost:4000/2017/03/08/why-would-people-want-fine-art-trained-machine-learning-models/"}</script>
<!-- End Jekyll SEO tag -->

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="shortcut icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">
	<link rel="icon" type="image/x-icon" href="https://apievangelist.com/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="Kin Lane" href="/feed.xml">
  <link rel="stylesheet" href="/assets/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/assets/css/font-awesome.min.css" />

  <script src="/assets/js/main.js"></script>

  
    <script>
function searchResults(form) {

    var currentItem = null;
    var search = document.getElementById(form);
    var results = document.getElementById(form + "-results");
    var toggle = document.getElementById(form + "-toggle");

    function removeActive() {
        for (i = 0; i < results.children.length; i++) {
            results.children[i].classList.remove("uk-background-muted");
        }
    }

    // Detect all clicks on the document
    document.addEventListener("click", function(event) {

        var isClickSearch = false;
        var isClickResults = false;
        var isClickSearchToggle = false;

        if (search !== null) {
            isClickSearch = search.contains(event.target);
        }

        if (results !== null) {
            isClickResults = results.contains(event.target);
        }

        if (toggle !== null) {
            isClickSearchToggle = toggle.contains(event.target);
        }

        if (isClickSearch || isClickSearchToggle) {
            results.style.display = "block";
        }        

        if (!isClickResults && !isClickSearch && !isClickSearchToggle) {
            results.style.display = "none";
        }        
        
    });    

    results.addEventListener("mouseover", function(event) {

        removeActive();
        event.target.parentElement.classList.add("uk-background-muted");
        currentItem = null;

    });

    results.addEventListener("mouseout", function(event) {
        event.target.parentElement.classList.remove("uk-background-muted");
    });


    search.addEventListener("keyup", function(event) {

        var resultItems = results.children;
        var resultCount = results.children.length;
                                
        if (event.keyCode === 40) {

            if (currentItem < (resultCount - 1)) {
                if (currentItem === null) {
                    currentItem = 0;
                } else {
                    removeActive();
                    currentItem++;
                }
                removeActive();
                resultItems[currentItem].classList.add("uk-background-muted");
            }
            
        } else if (event.keyCode === 38) {

            if (currentItem > 0) {
                if (currentItem === null) {
                    currentItem = 0;
                } else {
                    removeActive();
                    currentItem--;
                }
                removeActive();
                resultItems[currentItem].classList.add("uk-background-muted");
            }

        } else if (event.keyCode === 13) {

            resultItems[currentItem].children[0].click();

        }

    });

}
</script>
  
  

  <meta property="og:url" content="http://kinlane.com/2017/03/08/why-would-people-want-fine-art-trained-machine-learning-models/">
  <meta property="og:type" content="website">
  <meta property="og:title" content="Why Would People Want Fine Art Trained Machine Learning Models | Kin Lane">
  <meta property="og:site_name" content="Kin Lane">
  <meta property="og:description" content="The ramblings, thoughts, and channeling of Kin Lane.">
  <meta property="og:image"  content="">

  <meta name="twitter:url" content="http://kinlane.com/2017/03/08/why-would-people-want-fine-art-trained-machine-learning-models/">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Why Would People Want Fine Art Trained Machine Learning Models | Kin Lane">
  <meta name="twitter:site" content="Kin Lane">
  <meta name="twitter:description" content="The ramblings, thoughts, and channeling of Kin Lane.">

  
  
  <meta name="twitter:image" content="">

  <script src="/assets/js/jquery-latest.min.js" type="text/javascript" charset="utf-8"></script>
  <script src="/assets/js/bootstrap.min.js" type="text/javascript" charset="utf-8"></script>

</head>

    <body>

    
        <div data-uk-sticky="animation: uk-animation-slide-top; sel-target: .uk-navbar-container; cls-active: uk-navbar-sticky; cls-inactive: uk-navbar-transparent; top: 200">
    <nav class="uk-navbar-container">
        <div class="uk-container">
            <div data-uk-navbar>
                <div class="uk-navbar-left">
                    <a class="uk-navbar-item uk-logo uk-visible@m" href="/"><img src="https://kinlane-productions2.s3.amazonaws.com/kin-lane/kin.png" alt="Kin Lane" width="50"></a>
                    
                        <a class="uk-navbar-toggle uk-hidden@m" href="#offcanvas-docs" data-uk-toggle><span data-uk-navbar-toggle-icon></span> <span class="uk-margin-small-left">Docs</span></a>
                    

                    <ul class="uk-navbar-nav uk-visible@m">
                        
                            
                            
                            
                                
                                    
                                        <li><a href="/" >Home</a></li>
                                                                                                        
                                
                            
                        
                            
                            
                            
                                
                                    
                                        <li><a href="/blog/" >Stories</a></li>
                                                                                                        
                                
                            
                        
                            
                            
                            
                                
                                    
                                        <li><a href="/about/" >About</a></li>
                                                                                                        
                                
                            
                        
                            
                            
                            
                                
                                    
                                        <li><a href="/experiences/" >Experiences</a></li>
                                                                                                        
                                
                            
                        
                            
                            
                            
                                
                                    
                                        <li><a href="/deprogramming/" >Deprogramming</a></li>
                                                                                                        
                                
                            
                        
                            
                            
                            
                                
                                    
                                        <li><a href="/images/" >Images</a></li>
                                                                                                        
                                
                            
                        
                            
                            
                            
                                
                                    
                                        <li><a href="/videos/" >Videos</a></li>
                                                                                                        
                                
                            
                        
                            
                            
                            
                                
                                    
                                        <li><a href="/archives/" >Archives</a></li>
                                                                                                        
                                
                            
                        
                    </ul>
                </div>
                <div class="uk-navbar-center uk-hidden@m">
                    <a class="uk-navbar-item uk-logo" href="/"><img src="https://kinlane-productions2.s3.amazonaws.com/kin-lane/kin.png" alt="Kin Lane"></a>
                </div>
                <div class="uk-navbar-right">
                    
                        
                            <div>
                                <a id="search-navbar-toggle" class="uk-navbar-toggle" uk-search-icon href="#"></a>
                                <div class="uk-drop uk-background-default uk-border-rounded" uk-drop="mode: click; pos: left-center; offset: 0">
                                    <form class="uk-search uk-search-navbar uk-width-1-1" onsubmit="return false;">
                                        <input id="search-navbar" class="uk-search-input" type="search" placeholder="Search my brain" autofocus autocomplete="off">
                                    </form>
                                    <ul id="search-navbar-results" class="uk-position-absolute uk-width-1-1 uk-list"></ul>
                                </div>
                            </div>
                            <script>
                            SimpleJekyllSearch({
                                searchInput: document.getElementById('search-navbar'),
                                resultsContainer: document.getElementById('search-navbar-results'),
                                noResultsText: '<li class="no-results">No results found</li>',
                                searchResultTemplate: '<li><a href="{url}">{title}</a></li>',
                                json: "/search.json"
                            });
                            searchResults("search-navbar");
                            </script>
                        
                    

                    <ul class="uk-navbar-nav uk-visible@m">
                        
                            
                            
                            
                                
                                    <li><div class="uk-navbar-item"><a class="uk-button uk-button-success" href="/contact/" >Question?</a></div></li>
                                
                            
                        
                    </ul>

                    
                        <a class="uk-navbar-toggle uk-hidden@m" href="#offcanvas" data-uk-toggle><span data-uk-navbar-toggle-icon></span> <span class="uk-margin-small-left">Menu</span></a>
                    

                </div>
            </div>
        </div>
    </nav>
</div>
    

    <div class="uk-section">
    <div class="uk-container uk-container-xsmall">
        <article class="uk-article">

            <h1 class="uk-article-title">Why Would People Want Fine Art Trained Machine Learning Models</h1>

            <div class="uk-article-meta uk-margin-top uk-margin-medium-bottom uk-flex uk-flex-middle">
                


  
  <img class="uk-border-circle avatar" src="https://kinlane-productions2.s3.amazonaws.com/kin-lane/kin-lane-cartoon-questioning.png" alt="Kin Lane">


<div>
  
    Written by 
    <span itemprop="author" itemscope itemtype="http://schema.org/Person">
      <span itemprop="name">
        Kin Lane 
        
        
        
              
      </span>
    </span><br>
  
  <time datetime="2017-03-08T00:00:00-05:00" itemprop="datePublished">
    
    Mar 8, 2017
  </time>
</div>
            </div>

            <div class="article-content link-primary">
                <center><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/art-museum/art-museum_blue_brush.jpg" width="90%" align="center" style="padding: 5px;"></center>
                <p>I'm spending time on my <a href="http://algorithmic.rotoscope.work/">algorithmic rotoscope work</a>, and thinking about how the machine learning style textures I've been marking can be put to use. I'm trying to see things from different vantage points and develop a better understanding of how texture styles can be put to use in the regular world.</p>
<p>I am enjoying using image style filters in my writing. It gives me kind of a gamified layer to my photography and drone hobby that allows me to create actual images I can use in my work as the <a href="http://apievangelist.com">API Evangelist</a>. Having unique filtered images available for use in my writing is valuable to me--enough to justify the couple hundreds of dollars I spend each month on AWS servers.</p>
<p>I know why I like applying image styles to my photos, but why do others? Most of the image filters out there we've seen from apps like <a href="https://prisma-ai.com/">Prisma</a> are focused on fine art. Training image style transfer machine learning models on popular art that people are already familiar with. I guess this is allows people to apply the characteristics of art they like to the photographic layer of our increasingly digital lives.</p>
<p><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/art-museum/art-museum_blue_brush.jpg" alt="" width="100%" /></p>
<p>To me, it feels like some sort of art placebo. A way of superficially and algorithmic injecting what are brain tells us is artsy to our fairly empty, digital photo reality. Taking photos in real time isn't satisfying enough anymore. We need to distract ourselves from the world by applying reality to our digitally documented physical world--almost the opposite of augmented reality if there is such a thing. Getting lost in the ability to look at the real world through the algorithmic lens of our online life.</p>
<p><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/art-museum/art-museum_alien_goggles.jpg" alt="" width="100%" /></p>
<p>We are stealing the essence the meaningful, tangible art from our real world, and digitizing it. We take this essense and algorithmically apply it our everyday life trying to add some color, some texture, but not too much. We need the photos to still be meaningful, and have context in our life, but we need to be able to spray an algorithmic lacquer of meaning on our intangible lives.</p>
<p><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/art-museum/art-museum_crunch_paper.jpg" alt="" width="100%" /></p>
<p>The more filters we have, the more lenses we have to look at the exact same moment we live each day. We go to work. We go to school. We see the same scenery, the same people, and the same pictures each day. Now we are able to algorithmic shift, distort, and paint the picture of our lives we want to see.</p>
<p><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/art-museum/art-museum_dark_dali.jpg" alt="" width="100%" /></p>
<p>Now we can add color to our life. We are being trained to think we can change the palette, and are in control over our lives. We can colorize the old World War 2 era photos of our day, and choose whether we want to color within, or outside the lines. Our lives don't have to be just binary 1s and 0s, and black or white.</p>
<p><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/art-museum/art-museum_kandinsky_bv.jpg" alt="" width="100%" /></p>
<p>Slowly, picture by picture, algorithmic transfer by algorithmic transfer, the way we see the world changes. We no longer settle for the way things are, the way our mobile phone camera catches it. The digital version is the image we share with my friends, family, and the world. It should always be the most brilliant, the most colorful, and the painting that catches their eye and makes them stand in front of on the wall of your Facebook feed captivated.</p>
<p><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/art-museum/art-museum_sunday.jpg" alt="" width="100%" /></p>
<p>We no longer will remember what reality looks like, or what art looks like. Our collective social media memory will dictate what the world looks like. The number of likes will determine what is artistic, and what is beautiful or ugly. The algorithm will only show us what images match the world it wants us to see. Algorithmically, artistically painting the inside walls of our digital bubble.</p>
<p><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/art-museum/art-museum_blue_circuit_3.jpg" alt="" width="100%" /></p>
<p>Eventually, the sensors that stimulate us when we see photos will be well worn. They will be well programmed, with known inputs, and predictable outputs. The algorithm will be able to deliver exactly what we need, and correctly predict what we will need next. Scheduling up and queuing the next fifty possible scenarios--with exactly the right colors, textures, and meaning.</p>
<p><img src="https://s3.amazonaws.com/kinlane-productions2/algo-rotoscope/stories/art-museum/art-museum_copper_circuit_2.jpg" alt="" width="100%" /></p>
<p>How we see art will be forever changed by the algorithm. Our machines will never see art. Our machines will never know art. Our machines will only be able to transfer the characteristics we see and deliver them into newer, more relevant, timely, and meaningful images. Distilling down the essence of art into binary, and programming us to think this synthetic art is meaningful, and still applies to our physical world.</p>
<p>Like I said, I think people like applying artistic image filters to their mobile photos because it is the opposite of augmented reality. They are trying to augment their digital (hopes of reality) presence with the essence of what we (algorithm) think matters to use in the world. This process isn't about training a model to see art like some folks may tell you. It is about distilling down some of the most simple aspects of what our eyes see as art, and give this algorithm to our mobile phones and social networks to apply to the photograph digital logging of our physical reality. </p>
<p>It feels like this is about reprogramming people. It is about reprogramming what stimulates you. Automating an algorithmic view of what matters when it comes to art, and applying it to a digital view of matters in our daily worlds, via our social networks. Just one more area of our life where we are allowing algorithms to reprogram us, and bend our reality to be more digital.</p>
<p style="text-align: center;"><a href="https://umma.umaine.edu/">I Borrowed This Image From University of Maine Museum of Art</a></p>

                
                    <div class="share uk-text-center uk-margin-medium-top">
    
        <a class="uk-link-muted" href="https://twitter.com/intent/tweet?text=Why Would People Want Fine Art Trained Machine Learning Models&url=http://localhost:4000/2017/03/08/why-would-people-want-fine-art-trained-machine-learning-models/&via=&related=" rel="nofollow" target="_blank" title="Share on Twitter" onclick="window.open(this.href, 'twitter', 'width=550,height=235');return false;"><span data-uk-icon="icon: twitter; ratio: 1.2"></span></a>
    
    
        <a class="uk-link-muted uk-margin-small-left" href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2F2017%2F03%2F08%2Fwhy-would-people-want-fine-art-trained-machine-learning-models%2F" rel="nofollow" target="_blank" title="Share on Facebook" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;"><span data-uk-icon="icon: facebook; ratio: 1.2"></span></a>
    
</div>
                
            </div>

            <hr class="uk-margin-medium">

            <div class="uk-margin-large-top paginate-post">
    <div class="uk-child-width-expand@s uk-grid-large uk-pagi" data-uk-grid>
        <div>
            
                <div><a class="remove-underline hvr-back" href="/2017/03/08/the-oberservability-of-uber/">&larr; Previous</a></div>
            
        </div>
        <div>
            
                <div class="uk-text-right"><a class="remove-underline hvr-forward" href="/2017/03/10/machine-learning-will-be-a-vehicle-for-many-heists-in-the-future/">Next &rarr;</a></div>
            
        </div>
    </div>
</div>

            
        </article>

        <script>
            // Table of contents scroll to
            UIkit.scroll('#markdown-toc a', {
                duration: 400,
                offset: 120
            });
        </script>

    </div>
</div>


    <div id="offcanvas-docs" data-uk-offcanvas="overlay: true">
    <div class="uk-offcanvas-bar">

        <button class="uk-offcanvas-close" type="button" data-uk-close></button>

        

    </div>
</div>


    <div id="offcanvas" data-uk-offcanvas="flip: true; overlay: true">
    <div class="uk-offcanvas-bar">

        <a class="uk-logo uk-margin-small-bottom" href="/"><img src="https://kinlane-productions2.s3.amazonaws.com/kin-lane/kin.png" alt="Kin Lane"></a>
     
        <button class="uk-offcanvas-close" type="button" data-uk-close></button>
      
        <ul class="uk-nav uk-nav-primary uk-margin-top">
            
                

                

                
                    <li><a href="/" >Home</a></li>
                
            
                

                

                
                    <li><a href="/docs/installation/" >Docs</a></li>
                
            
                

                

                
                    <li><a href="/blog/" >Blog</a></li>
                
            
                

                

                
                    <li><a href="/changelog-timeline/" >Changelog</a></li>
                
            
                

                

                
                    <li><div class="uk-navbar-item"><a class="uk-button uk-button-success" href="/contact/" >Contact</a></div></li>
                
            
        </ul>

        <div class="uk-margin-top uk-text-center">
            <div data-uk-grid class="uk-child-width-auto uk-grid-small uk-flex-center uk-grid">
                
<div>
    <a rel="me" title="Mastodon" href="https://mastodon.kinlane.com/web/@kin" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/icons/mastodon-icon.png" width="18"></a>
</div>


<div class="uk-first-column">
    <a href="https://twitter.com/kinlane" title="Twitter" data-uk-icon="icon: twitter" class="uk-icon-link uk-icon" target="_blank"></a>
</div>


<div>
    <a href="https://www.facebook.com/kinlane" title="Facebook" data-uk-icon="icon: facebook" class="uk-icon-link uk-icon" target="_blank"></a>
</div>



<div>
    <a href="https://www.linkedin.com/in/kinlane/" title="LinkedIn" data-uk-icon="icon: linkedin" class="uk-icon-link uk-icon" target="_blank"></a>
</div>



<div>
    <a href="https://github.com/kinlane" title="GitHub" data-uk-icon="icon: github" class="uk-icon-link uk-icon" target="_blank"></a>
</div>



            </div>
        </div>

    </div>
</div>


    
        <footer class="uk-section uk-text-center uk-text-muted">
    <div class="uk-container uk-container-small">

        <div>
            <ul class="uk-subnav uk-flex-center">
                
                    
                    
                    
                        <li><a href="https://apievangelist.com" target="_blank" >API Evangelist</a></li>
                    
                
                    
                    
                    
                        <li><a href="https://algorithmic.rotoscope.work" target="_blank" >Algorotoscope</a></li>
                    
                
                    
                    
                    
                        <li><a href="http://alternate.kinlane.com" target="_blank" >Alternate Kin Lane</a></li>
                    
                
                    
                    
                    
                        <li><a href="http://dronerecovery.org" target="_blank" >Drone Recovery</a></li>
                    
                
            </ul>
        </div>
        <div class="uk-margin-medium">
            <div data-uk-grid class="uk-child-width-auto uk-grid-small uk-flex-center uk-grid">
                
<div>
    <a rel="me" title="Mastodon" href="https://mastodon.kinlane.com/web/@kin" target="_blank"><img src="https://kinlane-productions2.s3.amazonaws.com/icons/mastodon-icon.png" width="18"></a>
</div>


<div class="uk-first-column">
    <a href="https://twitter.com/kinlane" title="Twitter" data-uk-icon="icon: twitter" class="uk-icon-link uk-icon" target="_blank"></a>
</div>


<div>
    <a href="https://www.facebook.com/kinlane" title="Facebook" data-uk-icon="icon: facebook" class="uk-icon-link uk-icon" target="_blank"></a>
</div>



<div>
    <a href="https://www.linkedin.com/in/kinlane/" title="LinkedIn" data-uk-icon="icon: linkedin" class="uk-icon-link uk-icon" target="_blank"></a>
</div>



<div>
    <a href="https://github.com/kinlane" title="GitHub" data-uk-icon="icon: github" class="uk-icon-link uk-icon" target="_blank"></a>
</div>



            </div>
        </div>
        <div class="uk-margin-medium uk-text-small copyright link-secondary">Kin Lane</div>

    </div>
</footer>

    

    

    

    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1119465-35"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-1119465-35');
</script>


    </body>

</html>
